<!DOCTYPE html>
<!--[if IE 8]>
<html class="ie8" lang="zh">
<![endif]-->
<!--[if !(IE 8) ]><!-->
<html lang="zh"><!--<![endif]-->
  <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <title>翼图南</title>
        <link rel ="alternate" type="application/atom+xml"
                               title="翼图南 — Flux RSS"
                               href="https://wing2south.com/feeds/all.atom.xml" />
      <link rel="stylesheet" id="graphy-fonts-css" href="http://fonts.proxy.ustclug.org/css?family=Lato:400,700,400italic,700italic|Bitter:400&amp;subset=latin,latin-ext" type="text/css" media="all">
      <link rel="stylesheet" id="graphy-genericons-css" href="https://wing2south.com/theme/css/genericons.css" type="text/css" media="all">
      <link rel="stylesheet" href="https://wing2south.com/theme/css/style.min.css?1571737423.0">
      <link rel="stylesheet" href="https://wing2south.com/theme/css/typo.css?1571737423.0" type="text/css" media="all">

      <link rel="apple-touch-icon" sizes="57x57" href="/theme/icons/apple-touch-icon-57x57.png">
      <link rel="apple-touch-icon" sizes="60x60" href="/theme/icons/apple-touch-icon-60x60.png">
      <link rel="apple-touch-icon" sizes="72x72" href="/theme/icons/apple-touch-icon-72x72.png">
      <link rel="apple-touch-icon" sizes="76x76" href="/theme/icons/apple-touch-icon-76x76.png">
      <link rel="apple-touch-icon" sizes="114x114" href="/theme/icons/apple-touch-icon-114x114.png">
      <link rel="apple-touch-icon" sizes="120x120" href="/theme/icons/apple-touch-icon-120x120.png">
      <link rel="apple-touch-icon" sizes="144x144" href="/theme/icons/apple-touch-icon-144x144.png">
      <link rel="apple-touch-icon" sizes="152x152" href="/theme/icons/apple-touch-icon-152x152.png">
      <link rel="apple-touch-icon" sizes="180x180" href="/theme/icons/apple-touch-icon-180x180.png">
      <link rel="icon" type="image/png" href="/theme/icons/favicon-32x32.png" sizes="32x32">
      <link rel="icon" type="image/png" href="/theme/icons/android-chrome-192x192.png" sizes="192x192">
      <link rel="icon" type="image/png" href="/theme/icons/favicon-96x96.png" sizes="96x96">
      <link rel="icon" type="image/png" href="/theme/icons/favicon-16x16.png" sizes="16x16">
      <link rel="manifest" href="/theme/icons/manifest.json">
      <link rel="shortcut icon" href="/theme/icons/favicon.ico">
      <meta name="msapplication-TileColor" content="#da532c">
      <meta name="msapplication-TileImage" content="/theme/icons/mstile-144x144.png">
      <meta name="msapplication-config" content="/theme/icons/browserconfig.xml">
      <meta name="theme-color" content="#ffffff">
  </head>


  <body class="home blog no-sidebar footer-0 has-avatars">
    <div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
        <div class="site-branding">
          <h1 class="site-title"><a href="/" rel="home">翼图南</a></h1>
          <div class="site-description">故九萬里，則風斯在下矣，而後乃今培風；背負青天而莫之夭閼者，而後乃今將圖南</div>
        </div>

        <div class="main-navigation-wrapper">
          <nav id="site-navigation" class="main-navigation" role="navigation">
            <h1 class="menu-toggle">Menu</h1>
            <a class="skip-link screen-reader-text" href="#content">Skip to content</a>
            <div class="menu">
              <ul>
                <li class="current_page_item">
                  <a href="/">Home</a>
                </li>
                    <li><a href="https://wing2south.com/pages/gpg.html">GPG</a></li>
                  <li><a href="/cv.htm">CV</a></li>
                <li class="page_item page_item_has_children">
                  <a href="#">Categories</a>
                  <ul class="children">
                      <li class="page_item">
                        <a href="/category/code.html">Code</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/devops.html">Devops</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/django.html">Django</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/fen-xiang-lian-jie.html">分享链接</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/ji-qi-xue-xi.html">机器学习</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/machinelearning.html">MachineLearning</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/others.html">Others</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/productivity.html">Productivity</a>
                      </li>
                      <li class="page_item">
                        <a href="/category/python.html">Python</a>
                      </li>
                  </ul>
                </li>
                <li class="page_item">
                  <a href="/tags.html">Tags</a>
                </li>
                <li class="page_item page_item_has_children">
                  <a href="#">Social</a>
                  <ul class="children">
                      <li class="page_item">
                        <a href="https://twitter.com/glasslion">Twitter</a>
                      </li>
                      <li class="page_item">
                        <a href="https://github.com/glasslion">GitHub</a>
                      </li>
                      <li class="page_item">
                        <a href="http://stackoverflow.com/users/1093020/leonardo-z">StackOverflow</a>
                      </li>
                      <li class="page_item">
                        <a href="/images/wechat.jpg">微信二维码</a>
                      </li>
                  </ul>
                </li>
                  <li class="page_item">
                    <a href="https://wing2south.com/feeds/all.atom.xml" rel="alternate">Feed</a>
                  </li>
              </ul>
            </div><!-- .menu -->
            <form role="search" method="get" class="search-form" onsubmit="return google_search()">
            <label>
              <span class="screen-reader-text">Search for:</span>
              <input type="search" class="search-field" placeholder="Search …" value="" name="q" id="google_q" title="Search for:">
            </label>
            <input type="submit" class="search-submit" value="Search">
          </form>
          </nav><!-- #site-navigation -->
        </div>
      </header><!-- #masthead -->

      <div id="content" class="site-content">
        <div id="primary" class="content-area">
          <main id="main" class="site-main" role="main">

  <article class="post hentry typo">
    <header class="entry-header">
      <h1 class="entry-title">fastai 源码浅析 - LayerGroups</h1>
        <div class="entry-meta">
          <span class="posted-on">Posted on 
            <a href="https://wing2south.com/archives/2019/05/" rel="bookmark">
              <time class="entry-date published" datetime="2019-05-18T00:00:00+08:00">May 18, 2019</time>
            </a>
          </span>
          <span class="byline">by 
            <span class="author vcard">
              <a class="url fn n" href="https://wing2south.com/post/fastai-source-code-layer-group/">Leonardo Zhou</a>
            </span>
          </span>
          <span class="comments-link">· <a href="https://wing2south.com/post/fastai-source-code-layer-group/#comments" title="Comment on More Tags">Leave a comment</a>
          </span>
        </div><!-- .entry-meta -->
    </header>

    <div class="entry-content">
      <p>fastai 在使用预训练模型进行迁移学习(Transfer Learning)时， 有一项很酷的特性: 你可以给模型的 不同 layer 设置不同的 learning rate (Discriminative Learning Rates).</p>
<p>然而一些模型 如 ResNet 有很多层， 要给每一层都设置一个不同的 lr, 既麻烦也没有必要。其解决方法在 <strong><a href="https://course.fast.ai/">Practical Deep Learning for Coders, v3</a></strong> 课上， Jeremy 已经简略地提到过了。 fastai 会把 model 划分成若干个 layer groups, 给每个 group 设置一个不同的 learning rate。</p>
<p>其具体实现是怎样的?  不同结构的模型又是怎么划分 layer groupn 的? 对于新模型我们又应该怎样去设置 layer groups？ 要解答这些问题， 就需要我们自己来阅读源码了。</p>
<p>在通过 <code>cnn_learner()</code> 等方式创建 learner 时， 会调用 <code>learn.split()</code> 来对 model layers 分组:</p>
<p><strong>fastai/vision/learner.py</strong></p>
<div class="highlight snippet"><pre><span></span><span class="k">def</span> <span class="nf">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">:</span><span class="n">DataBunch</span><span class="p">,</span> <span class="n">base_arch</span><span class="p">:</span><span class="n">Callable</span><span class="o">...</span><span class="p">):</span>
    <span class="o">...</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_cnn_model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">learn</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">split_on</span> <span class="ow">or</span> <span class="n">meta</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">])</span>
</pre></div>


<p><strong><code>learn.split()</code> 会把分组结果存放在 learner 的 <code>layer_groups</code> 属性里:</strong></p>
<p><strong>fastai/basic_train.py</strong></p>
<div class="highlight snippet"><pre><span></span><span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split_on</span><span class="p">:</span><span class="n">SplitFuncOrIdxList</span><span class="p">)</span><span class="o">-&gt;</span><span class="bp">None</span><span class="p">:</span>
    <span class="s2">&quot;Split the model at `split_on`.&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">split_on</span><span class="p">,</span><span class="n">Callable</span><span class="p">):</span>
        <span class="n">split_on</span> <span class="o">=</span> <span class="n">split_on</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_groups</span> <span class="o">=</span> <span class="n">split_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">split_on</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>


<p><strong>一个 model 的 layer 分组方案， 其实是由 <code>split_on</code> 参数决定的。</strong>这个 <code>split_on</code> 参数可以在调用 <code>cnn_learner</code> 创建 learner 时手动传入， 缺省使用 模型 <code>meta</code> 配置里的 的 <code>split</code>参数。</p>
<p>fastai.vision 指定了以下几种 split_on 函数:
<strong>fastai/vision/learner.py</strong></p>
<div class="highlight snippet"><pre><span></span><span class="c1"># By default split models between first and second layer</span>
<span class="k">def</span> <span class="nf">_default_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>

<span class="c1"># Split a resnet style model</span>
<span class="k">def</span> <span class="nf">_resnet_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">6</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Split squeezenet model on maxpool layers</span>
<span class="k">def</span> <span class="nf">_squeezenet_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">5</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">8</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">_densenet_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">7</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">_vgg_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">22</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">_alexnet_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">6</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">_default_meta</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cut&#39;</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">_default_split</span><span class="p">}</span>
<span class="n">_resnet_meta</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cut&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">_resnet_split</span><span class="p">}</span>
<span class="n">_squeezenet_meta</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cut&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">_squeezenet_split</span><span class="p">}</span>
<span class="n">_densenet_meta</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cut&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">_densenet_split</span><span class="p">}</span>
<span class="n">_vgg_meta</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cut&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">_vgg_split</span><span class="p">}</span>
<span class="n">_alexnet_meta</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cut&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">:</span> <span class="n">_alexnet_split</span><span class="p">}</span>
</pre></div>


<p>然而光看这段代码， 我们仍然会一头雾水，<code>m[0][0][6]</code> ,  <code>m[1]</code>  这些 magic number 到底是怎样来的。</p>
<p>下面让我们以 alenxnet 为例, 深入看下这块的实现:</p>
<p>注: <code>fastai.vision.models</code> 下的很多模型是直接用的的 <code>torchvision</code> 里的模型</p>
<p><strong>torchvision/models/alexnet.py</strong></p>
<div class="highlight snippet"><pre><span></span><span class="k">class</span> <span class="nc">AlexNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlexNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">256</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>


<p>可以看出 <code>torchvision</code> 的实现里把 AlexNet Model 所有 layers 划分为了 3个  <code>nn.Sequential</code> 串:</p>
<ul>
<li>features</li>
<li>avgpool</li>
<li>classifier</li>
</ul>
<p>注: AlexNet 作为一种顺序模型， 其实只用一串 <code>nn.Sequential</code> 块 就可以实现了。 而<code>torchvision</code> 为了代码组织更加清晰和易用， 才按照 layer 的功能划分了 3串。</p>
<p>打印出来的模型结构如下:</p>
<div class="highlight snippet"><pre><span></span><span class="n">AlexNet</span><span class="p">(</span>
  <span class="p">(</span><span class="n">features</span><span class="p">):</span> <span class="n">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>
    <span class="p">...</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">...</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">avgpool</span><span class="p">):</span> <span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
  <span class="p">(</span><span class="n">classifier</span><span class="p">):</span> <span class="n">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">9216</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>
    <span class="p">...</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p>这里的AlexNet模型并不是我们最终使用的模型， 它的结构是针对 ImageNet 数据集设计的， 解决的是 1000个类别图片的分类问题， 因此我们还会对它进行改造:</p>
<p><code>cnn_learner()</code> 通过调用 <code>create_cnn_model()</code> 来创建 实际使用的模型:</p>
<p><strong>fastai/vision/learner.py</strong></p>
<div class="highlight snippet"><pre><span></span><span class="k">def</span> <span class="nf">create_cnn_model</span><span class="p">(</span><span class="n">base_arch</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="n">cut</span><span class="p">,</span> <span class="err">。。。</span><span class="p">):</span>
    <span class="s2">&quot;Create custom convnet architecture&quot;</span>
    <span class="n">body</span> <span class="o">=</span> <span class="n">create_body</span><span class="p">(</span><span class="n">base_arch</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">cut</span><span class="p">)</span>
    <span class="o">...</span>
    <span class="n">head</span> <span class="o">=</span> <span class="n">create_head</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="n">head</span><span class="p">)</span>
</pre></div>


<p>可见 fastai 创建出来的模型是由 body 和 head 两块拼接而成:</p>
<ul>
<li>
<p>body 是在预训练模型(e.g. AlexNet) 上 丢弃若干层网络得到的
 <code>create_body()</code> 具体会丢弃哪些层， 是由 model 的 <code>meta['cut']</code> 参数决定的。
在上文的 代码里， 我们可以看到 <code>_alexnet_meta['cut']</code> 的值为 -1. 这意味着丢弃 AlexNet 的最后一串 layer， 即前文提到的 <code>classifier</code> Sequential.</p>
</li>
<li>
<p>head 的结构只和我们的数据有多少类别有关， 和body 用的是alexnet, 还是 vgg 或 resnet 没有关系。 其具体结构， 下文会讲。</p>
</li>
</ul>
<p>最终的模型结构课简化如下:</p>
<div class="highlight snippet"><pre><span></span><span class="p">(</span>
    <span class="p">(</span><span class="n">body</span><span class="p">):</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="p">(</span><span class="n">avgpool</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">head</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p>现在 再回过头看 alexnet 的 <code>split_on</code> 函数就比较好理解了:</p>
<div class="highlight snippet"><pre><span></span><span class="k">def</span> <span class="nf">_alexnet_split</span><span class="p">(</span><span class="n">m</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">6</span><span class="p">],</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>


<p><code>m[0]</code> 为 <code>body</code>,  <code>m[0][0]</code> 即 <code>features</code>， <code>m[1]</code> 即 <code>head</code></p>
<p><code>(m[0][0][6], m[1])</code> 意味着  features 的 前6层 划为第一个 layer group, 第7层到 head 划分为第而个 layer group， head 作为第三个 layer group。</p>
<p>由于 head 层是我们自己添加的， 是预训练模型里不存在的, 它的 learning rate 显然应该和预训练模型不同， 这也是所有的 <code>split_on</code> 函数都包含 <code>m[1]</code> 这一项的原因。</p>
<p>至于 AlexNet 为什么选择在 <code>m[0][0][6]</code> 处切一下， vgg 在 <code>m[0][0][22]</code>切一下， resnet 在 <code>m[0][6]</code> 切一下， 经过分析这些模型的结构，可发现这些切割垫都是卷积层中间的位置。</p>
<h2>总结</h2>
<ul>
<li><code>meta['split']</code> 决定了 model 怎样划分 layer groups</li>
<li><code>meta['cut']</code> 决定了预训练模型会丢弃哪些层</li>
<li>绝大部分 CNN 模型会被划分为 3 个 layer group， 预训练模型的卷积层会从中间划分为 2 个 group, 分类器1个 group</li>
</ul>
    </div><!-- .entry-content -->
    <footer class="entry-meta entry-footer">
      <span class="cat-links">Posted in 
        <a href="https://wing2south.com/category/ji-qi-xue-xi.html" rel="category">机器学习</a>
      </span>
      <span class="tags-links">Tagged 
          <a href="https://wing2south.com/tag/fastai-pytorch.html" rel="tag">fastai pytorch</a>
      </span>
    </footer><!-- .entry-meta -->

  </article><!-- #post-## -->


  <nav class="navigation post-navigation" role="navigation">
    <div class="nav-links">
        <div class="nav-previous">
          <h2>Previous post</h2>
          <a href="https://wing2south.com/post/tensorflow-pytorch-devide-switch/" rel="prev">Tensorflow 和 PyTorch 如何快速切换使用的 CPU/GPU 设备</a>
        </div>
    </div><!-- .nav-links -->
  </nav><!-- .navigation -->

<div id="comments" class="comments-area">
  <hr />
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'wing2south';
    var disqus_identifier = "post/fastai-source-code-layer-group/";
    var disqus_title = "fastai 源码浅析 - LayerGroups";
    var disqus_url = "https://wing2south.com/post/fastai-source-code-layer-group/";
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus</a>.</noscript>
</div>  <!-- #comments -->
          </main><!-- #main -->
        </div><!-- #primary -->
      </div><!-- #content -->

      <footer id="colophon" class="site-footer" role="contentinfo">
            <div class="site-info">
          <div class="site-copyright">© 2019 <a href="https://wing2south.com" rel="home">翼图南</a></div>
          <div class="site-credit">Powered by <a href="http://blog.getpelican.com/">Pelican</a> &amp;
          <a href="http://wordpress.org/themes/graphy">Graphy</a>, hosted on <a href="https://github.com/">GitHub</a>.</div>
        </div><!-- .site-info -->
      </footer><!-- #colophon -->

    </div><!-- #page -->

  <script type="text/javascript" src="https://wing2south.com/theme/js/navigation.js?1571737423.0"></script>
  <script type="text/javascript" src="https://wing2south.com/theme/js/skip-link-focus-fix.js?1571737423.0"></script>
  <script type="text/javascript" src="https://wing2south.com/theme/js/google-search.js?1571737423.0"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-42951023-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>